{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://static1.squarespace.com/static/55d78486e4b038548bc9f33e/t/55ec5931e4b0518639da93c6/1448895140273/?format=1500w\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Joined Data\n",
    "\n",
    "In this notebook we will demonstrate how to join pandas DataFrames.  We will use this technique to join the accident and person tables from the FARS data set.  We will then train on the joined data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data\n",
    "\n",
    "Nothing much to see here.  We are loading the tables that we will work with as we have done many times before, using the pandas read_csv method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Chengyu/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "acc_df = pd.read_csv('../../data/train/accident_train.csv')\n",
    "per_df = pd.read_csv('../../data/train/person_train.csv')\n",
    "veh_df = pd.read_csv('../../data/train/vehicle_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Shared Columns\n",
    "\n",
    "Both the accident and person tables have several columns in common.  We want to join on just the 'ID' column.  When pandas sees columns with the same name, it makes a copy of one of them and then adds it to the joined DataFrame.  This adds redundant information to our data, and so we will avoid it by dropping the duplicate columns from one of the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a list of each set of columns, and instantiate a new list that will contain the shared columns.\n",
    "acc_cols = acc_df.columns.tolist()\n",
    "per_cols = per_df.columns.tolist()\n",
    "shared_cols = []\n",
    "\n",
    "# Go through each column in the accident table.  If the column is also in the person table, add\n",
    "# it to the list.\n",
    "for col in acc_cols:\n",
    "    if col in per_cols:\n",
    "        shared_cols.append(col)\n",
    "\n",
    "# ID is in both tables, but we will want to use it, so don't include it in the list of columns\n",
    "# to be removed.\n",
    "shared_cols.remove('ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining DataFrames in Pandas\n",
    "\n",
    "Pandas has a merge method that will join two DataFrames on a specified column.  We specify which columna and what type of join to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new joined DataFrame.\n",
    "# Note that we are dropping the shared columns from the person DataFrame before joining it to\n",
    "# the accident DataFrame.\n",
    "\n",
    "joined_df = pd.merge(acc_df, per_df.drop(shared_cols, axis=1), on='ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>VE_FORMS</th>\n",
       "      <th>PEDS</th>\n",
       "      <th>PERSONS</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>CITY</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>DAY</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>...</th>\n",
       "      <th>DEATH_HR</th>\n",
       "      <th>DEATH_MN</th>\n",
       "      <th>DEATH_TM</th>\n",
       "      <th>LAG_HRS</th>\n",
       "      <th>LAG_MINS</th>\n",
       "      <th>CERT_NO</th>\n",
       "      <th>WORK_INJ</th>\n",
       "      <th>HISPANIC</th>\n",
       "      <th>RACE</th>\n",
       "      <th>LOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>905</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>************</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>1644</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>************</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>35</td>\n",
       "      <td>1335</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>************</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>825</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>************</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>99</td>\n",
       "      <td>************</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>1930</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>************</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>99</td>\n",
       "      <td>************</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1700</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>************</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>99</td>\n",
       "      <td>************</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>************</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>************</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>812</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>************</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>99</td>\n",
       "      <td>************</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>99</td>\n",
       "      <td>************</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>99</td>\n",
       "      <td>************</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>99</td>\n",
       "      <td>************</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>99</td>\n",
       "      <td>************</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>99</td>\n",
       "      <td>************</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>************</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>99</td>\n",
       "      <td>************</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  STATE  VE_FORMS  PEDS  PERSONS  COUNTY  CITY  YEAR  DAY  MONTH  \\\n",
       "0    0      1         1     0        1      21     0  2003    1      1   \n",
       "1    1      1         1     0        1      71     0  2003    1      1   \n",
       "2    2      1         1     0        1      51     0  2003    5      1   \n",
       "3    3      1         1     0        1     111     0  2003    4      1   \n",
       "4    4      1         2     0        3      13     0  2003    1      1   \n",
       "5    4      1         2     0        3      13     0  2003    1      1   \n",
       "6    4      1         2     0        3      13     0  2003    1      1   \n",
       "7    5      1         1     0        1     101     0  2003   11      1   \n",
       "8    6      1         2     0        3      43     0  2003    4      1   \n",
       "9    6      1         2     0        3      43     0  2003    4      1   \n",
       "10   6      1         2     0        3      43     0  2003    4      1   \n",
       "11   7      1         1     0        1      61     0  2003   12      1   \n",
       "12   8      1         2     0       12      63     0  2003    8      1   \n",
       "13   8      1         2     0       12      63     0  2003    8      1   \n",
       "14   8      1         2     0       12      63     0  2003    8      1   \n",
       "15   8      1         2     0       12      63     0  2003    8      1   \n",
       "16   8      1         2     0       12      63     0  2003    8      1   \n",
       "17   8      1         2     0       12      63     0  2003    8      1   \n",
       "18   8      1         2     0       12      63     0  2003    8      1   \n",
       "19   8      1         2     0       12      63     0  2003    8      1   \n",
       "\n",
       "      ...     DEATH_HR  DEATH_MN  DEATH_TM  LAG_HRS  LAG_MINS       CERT_NO  \\\n",
       "0     ...            9         5       905        1        35  ************   \n",
       "1     ...           16        44      1644        0        54  ************   \n",
       "2     ...           13        35      1335        1        16  ************   \n",
       "3     ...            8        25       825        0        35  ************   \n",
       "4     ...            0         0         0      999        99  ************   \n",
       "5     ...           19        30      1930        0         0  ************   \n",
       "6     ...            0         0         0      999        99  ************   \n",
       "7     ...           17         0      1700        0        40  ************   \n",
       "8     ...            0         0         0      999        99  ************   \n",
       "9     ...           18         0      1800        0         0  ************   \n",
       "10    ...           18         0      1800        0         0  ************   \n",
       "11    ...            8        12       812        1         7  ************   \n",
       "12    ...            0         0         0      999        99  ************   \n",
       "13    ...            0         0         0      999        99  ************   \n",
       "14    ...            0         0         0      999        99  ************   \n",
       "15    ...            0         0         0      999        99  ************   \n",
       "16    ...            0         0         0      999        99  ************   \n",
       "17    ...            0         0         0      999        99  ************   \n",
       "18    ...            9         0       900        0         0  ************   \n",
       "19    ...            0         0         0      999        99  ************   \n",
       "\n",
       "   WORK_INJ  HISPANIC  RACE  LOCATION  \n",
       "0         9         7     1         0  \n",
       "1         0         7     1         0  \n",
       "2         0         7     2         0  \n",
       "3         0         1     1         0  \n",
       "4         8         0     0         0  \n",
       "5         0         7     2         0  \n",
       "6         8         0     0         0  \n",
       "7         0         7     1         0  \n",
       "8         8         0     0         0  \n",
       "9         0         7     7         0  \n",
       "10        0         7     1         0  \n",
       "11        0         7     1         0  \n",
       "12        8         0     0         0  \n",
       "13        8         0     0         0  \n",
       "14        8         0     0         0  \n",
       "15        8         0     0         0  \n",
       "16        8         0     0         0  \n",
       "17        8         0     0         0  \n",
       "18        0         1    98         0  \n",
       "19        8         0     0         0  \n",
       "\n",
       "[20 rows x 75 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we do a little bit more clean up, replacing missing data with 0, and removing the\n",
    "# 'CERT_NO' column, which is useless.  \n",
    "# We decided to make a bad_cols list so that more columns could be removed if you choose.\n",
    "\n",
    "bad_cols = ['CERT_NO']\n",
    "joined_df.drop(bad_cols, axis=1, inplace=True)\n",
    "joined_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on Joined Data\n",
    "\n",
    "Everything has been smooth sailing so far, but we are about to run into a wrinkle.  How should we train on the joined data?  Many of the accidents now have several rows describing them.  How should we deal with these duplicates?  How do we build a train_test_split on this data?\n",
    "\n",
    "For training, we will want to consider all the data about each accident in its entirety.  Thus, the pandas train_test_split method is insufficient for splitting this data for validation, as it may split a single accident into the training set and the test set.  We address this with the following voodoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = joined_df.groupby('ID')\n",
    "pd.DataFrame(grouped)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, get the index of each accident, and choose a subset of them for a train_test_split.\n",
    "indices = acc_df.ID.values\n",
    "num_indices = len(indices)\n",
    "test_size = int(num_indices*0.75)\n",
    "\n",
    "perm_indices = np.random.permutation(indices)\n",
    "train_indices = perm_indices[:test_size]\n",
    "test_indices = perm_indices[test_size:]\n",
    "\n",
    "# We will now group each accident by ID.\n",
    "grouped = joined_df.groupby('ID')\n",
    "\n",
    "# The grouped DataFrame has a dictionary attribute called indices.\n",
    "#\n",
    "# This dictionary maps an ID to the indices that correspond to the ID \n",
    "# in the joined table.  Thus, we can build new dictionaries that map\n",
    "# the ids in the training set to the corresponding rows in the joined table,\n",
    "# and similarly for the test set.\n",
    "\n",
    "tr_ids = {key : grouped.indices[key] for key in train_indices}\n",
    "te_ids = {key : grouped.indices[key] for key in test_indices}\n",
    "\n",
    "# Finally, we turn the dictionaries we created above into lists of row numbers.\n",
    "# We can then use these row numbers to build our train/test split.\n",
    "train_ids = []\n",
    "for key in tr_ids:\n",
    "    for ind in tr_ids[key].tolist():\n",
    "        train_ids.append(ind)\n",
    "\n",
    "test_ids = []\n",
    "for key in te_ids:\n",
    "    for ind in te_ids[key].tolist():\n",
    "        test_ids.append(ind)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the Xtrain and Xtest DataFrames.\n",
    "\n",
    "Xtrain = joined_df.ix[train_ids]\n",
    "Xtest = joined_df.ix[test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the Ytrain and Ytest DataFrames.\n",
    "Ytrain = Xtrain[['ID', 'DRUNK_DR']]\n",
    "Ytest = Xtest[['ID', 'DRUNK_DR']]\n",
    "\n",
    "# Drop some columns that aren't going to help us.\n",
    "Xtrain.drop(['DRUNK_DR', 'RAIL', 'TWAY_ID', 'YEAR'], axis=1, inplace=True)\n",
    "Xtest.drop(['DRUNK_DR', 'RAIL', 'TWAY_ID', 'YEAR'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtr = Xtrain.drop('ID', axis=1).values\n",
    "Ytr = Ytrain['DRUNK_DR'].values\n",
    "join_cols = Xtrain.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xte = Xtest.drop('ID', axis=1).values\n",
    "Yte = Ytest['DRUNK_DR'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hopefully all this work has paid off.  Build a RandomForestClassifier, train\n",
    "# a model, and make a prediction about the test set.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf1 = RandomForestClassifier()\n",
    "rf1.fit(Xtr, Ytr)\n",
    "\n",
    "yhat1 = rf1.predict_proba(Xte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidating Predictions on Joined Data\n",
    "\n",
    "We have one more wrinkle to iron out.  We have made a prediction for each row in the test set.  However, many accidents span several rows.  To evaluate our prediction, we need to make only one prediction per accident.\n",
    "\n",
    "There are several ways that we might do this.  Here, we group the predictions by ID, and then attach the mean of the predictions to each ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_df = pd.DataFrame({'ID':Ytest['ID'].values, 'prob':yhat1[:,1]})\n",
    "grouped_predict = predict_df.groupby('ID')\n",
    "prediction = grouped_predict.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This cell builds a RandomForestClassifier on the unmerged data, as we did\n",
    "# in our Getting Started With Fars notebook.\n",
    "\n",
    "acc_df.fillna(0, inplace=True)\n",
    "Xtrain = acc_df.ix[tr_ids].sort_index()\n",
    "Xtest = acc_df.ix[te_ids].sort_index()\n",
    "\n",
    "Ytrain = Xtrain[['ID', 'DRUNK_DR']]\n",
    "Ytest = Xtest[['ID', 'DRUNK_DR']]\n",
    "\n",
    "Xtrain.drop(['DRUNK_DR', 'RAIL', 'TWAY_ID', 'YEAR'], axis=1, inplace=True)\n",
    "Xtest.drop(['DRUNK_DR', 'RAIL', 'TWAY_ID', 'YEAR'], axis=1, inplace=True)\n",
    "\n",
    "Xtr = Xtrain.drop('ID',axis=1).values\n",
    "Ytr = Ytrain['DRUNK_DR'].values\n",
    "vanilla_cols = Xtrain.columns.tolist()\n",
    "\n",
    "rf2 = RandomForestClassifier()\n",
    "rf2.fit(Xtr, Ytr)\n",
    "\n",
    "Xte = Xtest.drop('ID',axis=1).values\n",
    "\n",
    "yhat2 = rf2.predict_proba(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we get the target that we were tryin to predict in order to make a comparison.\n",
    "Y = acc_df.ix[test_indices]['DRUNK_DR']\n",
    "Y = Y.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.82140707662144863, 0.7843366006725111)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the AUC score for our preditions.\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "\n",
    "auc1 = auc(Y.astype(int), prediction.values)\n",
    "auc2 = auc(Y.astype(int), yhat2[:,1])\n",
    "\n",
    "auc1, auc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "\n",
    "We have seen that adding the person data to the accident data yields a better prediction.  From here, we should do several things:\n",
    "\n",
    "1. Make a prediction on the entire training set and submit it to Kaggle.\n",
    "2. Incorporate the vehicle data to our models.\n",
    "3. Further clean the data.\n",
    "4. Tune the parameters on the RandomForestClassifier to see if you can get improvement.\n",
    "5. Try different models to see if they perform better than the RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "join_cols = join_cols[1:]\n",
    "vanilla_cols = vanilla_cols[1:]\n",
    "\n",
    "feat_imps1 = np.argsort(rf1.feature_importances_).tolist()\n",
    "feat_imps2 = np.argsort(rf2.feature_importances_).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Important Features for Vanilla Data\n",
      "\tSCH_BUS\n",
      "\tCF3\n",
      "\tCF2\n",
      "\tSP_JUR\n",
      "\tCF1\n",
      "\tFATALS\n",
      "\tVE_FORMS\n",
      "\tNHS\n",
      "\tWEATHER\n",
      "\tHOSP_HR\n",
      "\tMAN_COLL\n",
      "\tHOSP_MN\n",
      "\tNOT_HOUR\n",
      "\tPEDS\n",
      "\tROUTE\n",
      "\tPERSONS\n",
      "\tCITY\n",
      "\tNOT_MIN\n",
      "\tROAD_FNC\n",
      "\tARR_MIN\n",
      "Most Important Features for Joined Data\n",
      "\tCF3\n",
      "\tEMER_USE\n",
      "\tCF2\n",
      "\tSCH_BUS\n",
      "\tSPEC_USE\n",
      "\tFIRE_EXP\n",
      "\tSP_JUR\n",
      "\tLOCATION\n",
      "\tTOW_VEH\n",
      "\tWORK_INJ\n",
      "\tEXTRICAT\n",
      "\tPER_TYP\n",
      "\tCF1\n",
      "\tHISPANIC\n",
      "\tRACE\n",
      "\tEJECTION\n",
      "\tSEX\n",
      "\tPER_NO\n",
      "\tHOSPITAL\n",
      "\tDOA\n"
     ]
    }
   ],
   "source": [
    "print('Most Important Features for Vanilla Data')\n",
    "for feat in feat_imps2[:20]:\n",
    "    print('\\t'+vanilla_cols[feat])\n",
    "\n",
    "print('Most Important Features for Joined Data')\n",
    "for feat in feat_imps1[:20]:\n",
    "    print('\\t'+join_cols[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 35)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rf2.feature_importances_), len(vanilla_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
